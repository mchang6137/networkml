2017-04-04 02:52:15.368211: step 0, loss = 13.06 (4.0 examples/sec; 7.993 sec/batch)
2017-04-04 02:52:36.674287: step 10, loss = 13.46 (22.7 examples/sec; 1.408 sec/batch)
2017-04-04 02:52:50.805103: step 20, loss = 14.42 (22.7 examples/sec; 1.412 sec/batch)
2017-04-04 02:53:04.984322: step 30, loss = 14.82 (22.5 examples/sec; 1.421 sec/batch)
2017-04-04 02:53:19.210737: step 40, loss = 14.52 (22.5 examples/sec; 1.420 sec/batch)
2017-04-04 02:53:33.473924: step 50, loss = 13.51 (22.4 examples/sec; 1.427 sec/batch)
2017-04-04 02:53:47.757161: step 60, loss = 13.12 (22.4 examples/sec; 1.430 sec/batch)
2017-04-04 02:54:02.078093: step 70, loss = 12.83 (22.3 examples/sec; 1.433 sec/batch)
2017-04-04 02:54:16.420930: step 80, loss = 13.09 (22.3 examples/sec; 1.434 sec/batch)
2017-04-04 02:54:30.790089: step 90, loss = 13.05 (22.3 examples/sec; 1.437 sec/batch)
2017-04-04 02:54:45.179800: step 100, loss = 12.88 (22.2 examples/sec; 1.440 sec/batch)
2017-04-04 02:55:01.256339: step 110, loss = 13.02 (22.1 examples/sec; 1.450 sec/batch)
2017-04-04 02:55:15.723344: step 120, loss = 12.86 (22.1 examples/sec; 1.448 sec/batch)
2017-04-04 02:55:30.201836: step 130, loss = 12.88 (22.1 examples/sec; 1.447 sec/batch)
2017-04-04 02:55:44.694841: step 140, loss = 12.90 (21.9 examples/sec; 1.458 sec/batch)
2017-04-04 02:55:59.225665: step 150, loss = 13.01 (22.0 examples/sec; 1.456 sec/batch)
2017-04-04 02:56:13.768740: step 160, loss = 12.71 (22.0 examples/sec; 1.454 sec/batch)
2017-04-04 02:56:28.315929: step 170, loss = 12.87 (22.0 examples/sec; 1.457 sec/batch)
2017-04-04 02:56:42.900413: step 180, loss = 12.71 (21.9 examples/sec; 1.460 sec/batch)
2017-04-04 02:56:57.474129: step 190, loss = 12.63 (22.0 examples/sec; 1.454 sec/batch)
2017-04-04 02:57:12.065753: step 200, loss = 12.76 (22.0 examples/sec; 1.454 sec/batch)
2017-04-04 02:57:28.177439: step 210, loss = 12.76 (21.9 examples/sec; 1.458 sec/batch)
2017-04-04 02:57:42.781294: step 220, loss = 12.75 (21.9 examples/sec; 1.459 sec/batch)
2017-04-04 02:57:57.414612: step 230, loss = 12.86 (21.9 examples/sec; 1.458 sec/batch)
2017-04-04 02:58:12.036740: step 240, loss = 12.66 (21.9 examples/sec; 1.461 sec/batch)
2017-04-04 02:58:26.672895: step 250, loss = 12.71 (21.8 examples/sec; 1.466 sec/batch)
2017-04-04 02:58:41.310204: step 260, loss = 12.83 (21.8 examples/sec; 1.469 sec/batch)
2017-04-04 02:58:55.936198: step 270, loss = 12.75 (21.9 examples/sec; 1.462 sec/batch)
2017-04-04 02:59:10.553834: step 280, loss = 12.70 (22.0 examples/sec; 1.456 sec/batch)
2017-04-04 02:59:25.174889: step 290, loss = 12.63 (21.9 examples/sec; 1.462 sec/batch)
2017-04-04 02:59:39.791621: step 300, loss = 12.68 (21.9 examples/sec; 1.461 sec/batch)
2017-04-04 02:59:56.003722: step 310, loss = 12.67 (22.0 examples/sec; 1.456 sec/batch)
2017-04-04 03:00:10.648678: step 320, loss = 12.54 (21.9 examples/sec; 1.462 sec/batch)
2017-04-04 03:00:25.297944: step 330, loss = 12.65 (21.9 examples/sec; 1.459 sec/batch)
2017-04-04 03:00:39.944909: step 340, loss = 12.55 (21.9 examples/sec; 1.464 sec/batch)
2017-04-04 03:00:54.580922: step 350, loss = 12.76 (21.8 examples/sec; 1.467 sec/batch)
2017-04-04 03:01:09.222986: step 360, loss = 12.59 (21.7 examples/sec; 1.472 sec/batch)
2017-04-04 03:01:23.875136: step 370, loss = 12.74 (21.8 examples/sec; 1.470 sec/batch)
2017-04-04 03:01:38.520852: step 380, loss = 12.67 (21.8 examples/sec; 1.471 sec/batch)
2017-04-04 03:01:53.147866: step 390, loss = 12.53 (21.9 examples/sec; 1.460 sec/batch)
2017-04-04 03:02:07.779719: step 400, loss = 12.68 (21.9 examples/sec; 1.459 sec/batch)
2017-04-04 03:02:23.913924: step 410, loss = 12.72 (21.9 examples/sec; 1.462 sec/batch)
2017-04-04 03:02:38.572617: step 420, loss = 12.58 (21.9 examples/sec; 1.462 sec/batch)
2017-04-04 03:02:53.218515: step 430, loss = 12.70 (21.9 examples/sec; 1.461 sec/batch)
2017-04-04 03:03:07.873391: step 440, loss = 12.56 (21.9 examples/sec; 1.460 sec/batch)
2017-04-04 03:03:22.515843: step 450, loss = 12.50 (21.9 examples/sec; 1.461 sec/batch)
2017-04-04 03:03:37.161521: step 460, loss = 12.48 (21.8 examples/sec; 1.468 sec/batch)
2017-04-04 03:03:51.807120: step 470, loss = 12.47 (21.8 examples/sec; 1.469 sec/batch)
2017-04-04 03:04:06.452682: step 480, loss = 12.46 (21.8 examples/sec; 1.468 sec/batch)
2017-04-04 03:04:21.090565: step 490, loss = 12.70 (21.8 examples/sec; 1.470 sec/batch)
2017-04-04 03:04:35.733253: step 500, loss = 12.58 (21.8 examples/sec; 1.468 sec/batch)
2017-04-04 03:04:51.861116: step 510, loss = 12.57 (21.8 examples/sec; 1.465 sec/batch)
2017-04-04 03:05:06.485396: step 520, loss = 12.66 (21.9 examples/sec; 1.459 sec/batch)
2017-04-04 03:05:21.118626: step 530, loss = 12.42 (21.9 examples/sec; 1.464 sec/batch)
2017-04-04 03:05:35.754327: step 540, loss = 12.59 (21.8 examples/sec; 1.468 sec/batch)
2017-04-04 03:05:50.393011: step 550, loss = 12.58 (21.8 examples/sec; 1.467 sec/batch)
2017-04-04 03:06:05.023114: step 560, loss = 12.55 (21.9 examples/sec; 1.458 sec/batch)
2017-04-04 03:06:19.657908: step 570, loss = 12.43 (21.9 examples/sec; 1.461 sec/batch)
2017-04-04 03:06:34.299138: step 580, loss = 12.60 (21.9 examples/sec; 1.458 sec/batch)
2017-04-04 03:06:48.951408: step 590, loss = 12.59 (21.9 examples/sec; 1.459 sec/batch)
2017-04-04 03:07:03.595368: step 600, loss = 12.61 (21.9 examples/sec; 1.460 sec/batch)
2017-04-04 03:07:19.754359: step 610, loss = 12.42 (21.9 examples/sec; 1.462 sec/batch)
2017-04-04 03:07:34.405008: step 620, loss = 12.52 (21.9 examples/sec; 1.462 sec/batch)
2017-04-04 03:07:49.050415: step 630, loss = 12.50 (21.9 examples/sec; 1.458 sec/batch)
2017-04-04 03:08:03.694388: step 640, loss = 12.48 (21.8 examples/sec; 1.468 sec/batch)
2017-04-04 03:08:18.338869: step 650, loss = 12.36 (21.8 examples/sec; 1.465 sec/batch)
2017-04-04 03:08:32.972413: step 660, loss = 12.48 (21.8 examples/sec; 1.470 sec/batch)
2017-04-04 03:08:47.619569: step 670, loss = 12.42 (21.7 examples/sec; 1.474 sec/batch)
2017-04-04 03:09:02.275264: step 680, loss = 12.32 (21.7 examples/sec; 1.473 sec/batch)
2017-04-04 03:09:16.926237: step 690, loss = 12.29 (21.8 examples/sec; 1.471 sec/batch)
2017-04-04 03:09:31.586729: step 700, loss = 12.67 (21.8 examples/sec; 1.469 sec/batch)
2017-04-04 03:09:47.734805: step 710, loss = 12.46 (21.8 examples/sec; 1.467 sec/batch)
2017-04-04 03:10:02.381501: step 720, loss = 12.63 (21.8 examples/sec; 1.471 sec/batch)
2017-04-04 03:10:17.023477: step 730, loss = 12.69 (21.8 examples/sec; 1.469 sec/batch)
2017-04-04 03:10:31.682130: step 740, loss = 12.49 (21.8 examples/sec; 1.470 sec/batch)
2017-04-04 03:10:46.322561: step 750, loss = 12.47 (21.9 examples/sec; 1.463 sec/batch)
2017-04-04 03:11:00.970556: step 760, loss = 12.33 (21.8 examples/sec; 1.468 sec/batch)
2017-04-04 03:11:15.600916: step 770, loss = 12.52 (21.9 examples/sec; 1.463 sec/batch)
2017-04-04 03:11:30.230889: step 780, loss = 12.37 (21.9 examples/sec; 1.458 sec/batch)
2017-04-04 03:11:44.868058: step 790, loss = 12.58 (21.8 examples/sec; 1.469 sec/batch)
2017-04-04 03:11:59.508983: step 800, loss = 12.30 (21.8 examples/sec; 1.468 sec/batch)
2017-04-04 03:12:15.675572: step 810, loss = 12.39 (21.8 examples/sec; 1.466 sec/batch)
2017-04-04 03:12:30.327822: step 820, loss = 12.48 (21.8 examples/sec; 1.469 sec/batch)
2017-04-04 03:12:44.977376: step 830, loss = 12.32 (21.8 examples/sec; 1.470 sec/batch)
2017-04-04 03:12:59.626476: step 840, loss = 12.39 (21.8 examples/sec; 1.469 sec/batch)
2017-04-04 03:13:14.266155: step 850, loss = 12.40 (21.8 examples/sec; 1.465 sec/batch)
2017-04-04 03:13:28.916339: step 860, loss = 12.42 (21.8 examples/sec; 1.466 sec/batch)
2017-04-04 03:13:43.559080: step 870, loss = 12.56 (21.8 examples/sec; 1.471 sec/batch)
2017-04-04 03:13:58.205905: step 880, loss = 12.38 (21.8 examples/sec; 1.469 sec/batch)
2017-04-04 03:14:12.843922: step 890, loss = 12.18 (21.8 examples/sec; 1.465 sec/batch)
2017-04-04 03:14:27.470920: step 900, loss = 12.35 (21.9 examples/sec; 1.462 sec/batch)
2017-04-04 03:14:43.803344: step 910, loss = 12.65 (21.9 examples/sec; 1.458 sec/batch)
2017-04-04 03:14:58.452395: step 920, loss = 12.51 (21.9 examples/sec; 1.458 sec/batch)
2017-04-04 03:15:13.099058: step 930, loss = 12.35 (21.8 examples/sec; 1.467 sec/batch)
2017-04-04 03:15:27.746707: step 940, loss = 12.45 (21.8 examples/sec; 1.468 sec/batch)
2017-04-04 03:15:42.399507: step 950, loss = 12.57 (21.8 examples/sec; 1.466 sec/batch)
2017-04-04 03:15:57.038802: step 960, loss = 12.41 (21.8 examples/sec; 1.466 sec/batch)
2017-04-04 03:16:11.677317: step 970, loss = 12.53 (21.8 examples/sec; 1.471 sec/batch)
2017-04-04 03:16:26.339512: step 980, loss = 12.35 (21.8 examples/sec; 1.465 sec/batch)
2017-04-04 03:16:40.966312: step 990, loss = 12.35 (21.8 examples/sec; 1.466 sec/batch)
2017-04-04 03:16:55.617893: step 1000, loss = 12.19 (21.8 examples/sec; 1.468 sec/batch)