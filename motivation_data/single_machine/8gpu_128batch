2017-04-04 05:11:47.436934: step 0, loss = 13.03 (2.2 examples/sec; 57.906 sec/batch)
2017-04-04 05:12:23.906680: step 10, loss = 13.03 (126.6 examples/sec; 1.011 sec/batch)
2017-04-04 05:12:33.922174: step 20, loss = 13.60 (126.4 examples/sec; 1.013 sec/batch)
2017-04-04 05:12:44.752587: step 30, loss = 13.26 (111.2 examples/sec; 1.151 sec/batch)
2017-04-04 05:12:55.334812: step 40, loss = 13.19 (126.0 examples/sec; 1.016 sec/batch)
2017-04-04 05:13:06.047581: step 50, loss = 12.75 (125.6 examples/sec; 1.019 sec/batch)
2017-04-04 05:13:16.427689: step 60, loss = 13.24 (120.1 examples/sec; 1.066 sec/batch)
2017-04-04 05:13:26.793683: step 70, loss = 13.39 (123.8 examples/sec; 1.034 sec/batch)
2017-04-04 05:13:36.951921: step 80, loss = 12.88 (118.0 examples/sec; 1.085 sec/batch)
2017-04-04 05:13:47.403013: step 90, loss = 13.09 (109.0 examples/sec; 1.175 sec/batch)
2017-04-04 05:13:58.021659: step 100, loss = 12.39 (119.7 examples/sec; 1.070 sec/batch)
2017-04-04 05:14:09.995753: step 110, loss = 12.82 (115.0 examples/sec; 1.113 sec/batch)
2017-04-04 05:14:20.933634: step 120, loss = 12.59 (125.0 examples/sec; 1.024 sec/batch)
2017-04-04 05:14:31.615500: step 130, loss = 12.62 (124.2 examples/sec; 1.031 sec/batch)
2017-04-04 05:14:41.943274: step 140, loss = 12.61 (124.7 examples/sec; 1.027 sec/batch)
2017-04-04 05:14:52.372683: step 150, loss = 12.60 (124.1 examples/sec; 1.031 sec/batch)
2017-04-04 05:15:02.799280: step 160, loss = 12.69 (119.7 examples/sec; 1.069 sec/batch)
2017-04-04 05:15:13.416906: step 170, loss = 12.49 (115.8 examples/sec; 1.105 sec/batch)
2017-04-04 05:15:24.074236: step 180, loss = 12.50 (121.9 examples/sec; 1.050 sec/batch)
2017-04-04 05:15:34.639194: step 190, loss = 12.71 (125.2 examples/sec; 1.022 sec/batch)
2017-04-04 05:15:44.837104: step 200, loss = 12.40 (124.3 examples/sec; 1.030 sec/batch)
2017-04-04 05:15:56.111996: step 210, loss = 12.48 (123.5 examples/sec; 1.036 sec/batch)
2017-04-04 05:16:06.298285: step 220, loss = 12.74 (122.6 examples/sec; 1.044 sec/batch)
2017-04-04 05:16:17.263748: step 230, loss = 12.47 (109.3 examples/sec; 1.172 sec/batch)
2017-04-04 05:16:27.898130: step 240, loss = 12.46 (111.8 examples/sec; 1.145 sec/batch)
2017-04-04 05:16:38.580089: step 250, loss = 12.25 (111.9 examples/sec; 1.144 sec/batch)
2017-04-04 05:16:49.061420: step 260, loss = 12.55 (119.7 examples/sec; 1.070 sec/batch)
2017-04-04 05:16:59.485525: step 270, loss = 12.43 (122.9 examples/sec; 1.042 sec/batch)
2017-04-04 05:17:09.904473: step 280, loss = 12.06 (117.3 examples/sec; 1.091 sec/batch)
2017-04-04 05:17:20.358388: step 290, loss = 12.72 (119.9 examples/sec; 1.068 sec/batch)
2017-04-04 05:17:31.080322: step 300, loss = 12.53 (125.2 examples/sec; 1.022 sec/batch)
2017-04-04 05:17:43.031030: step 310, loss = 12.61 (118.3 examples/sec; 1.082 sec/batch)
2017-04-04 05:17:53.552233: step 320, loss = 12.66 (114.6 examples/sec; 1.117 sec/batch)
2017-04-04 05:18:03.653044: step 330, loss = 12.39 (124.9 examples/sec; 1.025 sec/batch)
2017-04-04 05:18:14.005139: step 340, loss = 12.35 (122.2 examples/sec; 1.048 sec/batch)
2017-04-04 05:18:24.279256: step 350, loss = 12.54 (120.1 examples/sec; 1.066 sec/batch)
2017-04-04 05:18:34.736277: step 360, loss = 12.74 (111.8 examples/sec; 1.145 sec/batch)
2017-04-04 05:18:45.529364: step 370, loss = 12.89 (123.2 examples/sec; 1.039 sec/batch)
2017-04-04 05:18:56.287867: step 380, loss = 12.26 (124.1 examples/sec; 1.031 sec/batch)
2017-04-04 05:19:06.677397: step 390, loss = 12.57 (123.5 examples/sec; 1.036 sec/batch)
2017-04-04 05:19:17.169868: step 400, loss = 12.29 (128.5 examples/sec; 0.996 sec/batch)
2017-04-04 05:19:28.687386: step 410, loss = 12.24 (121.6 examples/sec; 1.053 sec/batch)
2017-04-04 05:19:39.059571: step 420, loss = 12.28 (126.6 examples/sec; 1.011 sec/batch)
2017-04-04 05:19:49.875602: step 430, loss = 12.52 (119.6 examples/sec; 1.071 sec/batch)
2017-04-04 05:20:00.282299: step 440, loss = 12.53 (123.6 examples/sec; 1.036 sec/batch)
2017-04-04 05:20:10.860160: step 450, loss = 12.21 (124.7 examples/sec; 1.026 sec/batch)
2017-04-04 05:20:21.212526: step 460, loss = 12.48 (123.9 examples/sec; 1.033 sec/batch)
2017-04-04 05:20:31.638085: step 470, loss = 12.41 (121.1 examples/sec; 1.057 sec/batch)
2017-04-04 05:20:42.012242: step 480, loss = 12.46 (118.5 examples/sec; 1.080 sec/batch)
2017-04-04 05:20:52.435480: step 490, loss = 12.16 (125.2 examples/sec; 1.022 sec/batch)
2017-04-04 05:21:03.625875: step 500, loss = 12.14 (102.0 examples/sec; 1.255 sec/batch)
2017-04-04 05:21:15.746157: step 510, loss = 12.21 (121.9 examples/sec; 1.050 sec/batch)
2017-04-04 05:21:26.197261: step 520, loss = 12.38 (122.6 examples/sec; 1.044 sec/batch)
2017-04-04 05:21:36.537278: step 530, loss = 12.08 (124.5 examples/sec; 1.028 sec/batch)
2017-04-04 05:21:46.752207: step 540, loss = 12.28 (122.7 examples/sec; 1.043 sec/batch)
2017-04-04 05:21:57.277845: step 550, loss = 12.13 (102.7 examples/sec; 1.246 sec/batch)
2017-04-04 05:22:08.061425: step 560, loss = 12.43 (109.9 examples/sec; 1.165 sec/batch)
2017-04-04 05:22:18.720562: step 570, loss = 11.82 (122.1 examples/sec; 1.048 sec/batch)
2017-04-04 05:22:29.014785: step 580, loss = 12.43 (123.7 examples/sec; 1.035 sec/batch)
2017-04-04 05:22:39.304533: step 590, loss = 12.37 (122.4 examples/sec; 1.045 sec/batch)
2017-04-04 05:22:49.511454: step 600, loss = 12.45 (121.6 examples/sec; 1.053 sec/batch)
2017-04-04 05:23:01.044350: step 610, loss = 12.00 (116.8 examples/sec; 1.096 sec/batch)
2017-04-04 05:23:11.525977: step 620, loss = 12.21 (112.7 examples/sec; 1.136 sec/batch)
2017-04-04 05:23:22.360759: step 630, loss = 12.20 (113.3 examples/sec; 1.129 sec/batch)
2017-04-04 05:23:33.075480: step 640, loss = 12.18 (117.8 examples/sec; 1.086 sec/batch)
2017-04-04 05:23:43.265522: step 650, loss = 12.22 (124.2 examples/sec; 1.031 sec/batch)
2017-04-04 05:23:53.553679: step 660, loss = 12.23 (130.2 examples/sec; 0.983 sec/batch)
2017-04-04 05:24:03.930003: step 670, loss = 12.38 (125.8 examples/sec; 1.018 sec/batch)
2017-04-04 05:24:14.435986: step 680, loss = 11.93 (120.5 examples/sec; 1.062 sec/batch)
2017-04-04 05:24:25.080651: step 690, loss = 12.21 (124.2 examples/sec; 1.030 sec/batch)
2017-04-04 05:24:35.911804: step 700, loss = 12.02 (110.3 examples/sec; 1.160 sec/batch)
2017-04-04 05:24:47.565223: step 710, loss = 12.15 (123.0 examples/sec; 1.040 sec/batch)
2017-04-04 05:24:57.829506: step 720, loss = 11.71 (133.2 examples/sec; 0.961 sec/batch)
2017-04-04 05:25:08.172383: step 730, loss = 12.43 (121.5 examples/sec; 1.054 sec/batch)
2017-04-04 05:25:18.482551: step 740, loss = 12.23 (114.9 examples/sec; 1.114 sec/batch)
2017-04-04 05:25:28.978425: step 750, loss = 12.06 (125.9 examples/sec; 1.016 sec/batch)
2017-04-04 05:25:39.541389: step 760, loss = 12.14 (121.4 examples/sec; 1.055 sec/batch)
2017-04-04 05:25:50.062535: step 770, loss = 12.11 (123.0 examples/sec; 1.041 sec/batch)
2017-04-04 05:26:00.358173: step 780, loss = 12.02 (127.7 examples/sec; 1.002 sec/batch)
2017-04-04 05:26:10.592455: step 790, loss = 12.04 (133.0 examples/sec; 0.962 sec/batch)
2017-04-04 05:26:20.874759: step 800, loss = 12.79 (123.4 examples/sec; 1.037 sec/batch)
2017-04-04 05:26:32.575571: step 810, loss = 11.72 (123.6 examples/sec; 1.036 sec/batch)
2017-04-04 05:26:43.290198: step 820, loss = 11.80 (112.3 examples/sec; 1.139 sec/batch)
2017-04-04 05:26:53.808151: step 830, loss = 11.56 (124.0 examples/sec; 1.033 sec/batch)
2017-04-04 05:27:04.097861: step 840, loss = 11.97 (124.1 examples/sec; 1.032 sec/batch)
2017-04-04 05:27:14.453389: step 850, loss = 12.03 (120.9 examples/sec; 1.059 sec/batch)
2017-04-04 05:27:24.967598: step 860, loss = 11.71 (118.2 examples/sec; 1.083 sec/batch)
2017-04-04 05:27:35.561669: step 870, loss = 11.88 (124.8 examples/sec; 1.026 sec/batch)
2017-04-04 05:27:45.959575: step 880, loss = 12.31 (122.8 examples/sec; 1.043 sec/batch)
2017-04-04 05:27:56.716334: step 890, loss = 12.34 (115.0 examples/sec; 1.113 sec/batch)
2017-04-04 05:28:07.086378: step 900, loss = 11.97 (122.8 examples/sec; 1.042 sec/batch)
2017-04-04 05:28:18.564495: step 910, loss = 11.93 (123.1 examples/sec; 1.039 sec/batch)
2017-04-04 05:28:28.822659: step 920, loss = 12.01 (126.7 examples/sec; 1.010 sec/batch)
2017-04-04 05:28:39.444073: step 930, loss = 12.58 (119.7 examples/sec; 1.069 sec/batch)
2017-04-04 05:28:50.011110: step 940, loss = 11.44 (119.7 examples/sec; 1.069 sec/batch)
2017-04-04 05:29:00.523428: step 950, loss = 11.95 (110.4 examples/sec; 1.160 sec/batch)
2017-04-04 05:29:11.255781: step 960, loss = 12.04 (120.1 examples/sec; 1.065 sec/batch)
2017-04-04 05:29:21.675024: step 970, loss = 12.07 (134.9 examples/sec; 0.949 sec/batch)
2017-04-04 05:29:32.006385: step 980, loss = 11.67 (119.9 examples/sec; 1.068 sec/batch)
2017-04-04 05:29:42.318789: step 990, loss = 11.76 (124.4 examples/sec; 1.029 sec/batch)
2017-04-04 05:29:52.883032: step 1000, loss = 12.10 (123.5 examples/sec; 1.036 sec/batch)
2017-04-04 05:30:05.593631: step 1010, loss = 12.23 (119.1 examples/sec; 1.074 sec/batch)
2017-04-04 05:30:16.618870: step 1020, loss = 11.64 (114.2 examples/sec; 1.121 sec/batch)
2017-04-04 05:30:27.012842: step 1030, loss = 11.88 (122.5 examples/sec; 1.045 sec/batch)
2017-04-04 05:30:37.431188: step 1040, loss = 11.97 (121.6 examples/sec; 1.053 sec/batch)
2017-04-04 05:30:47.819326: step 1050, loss = 11.70 (121.2 examples/sec; 1.056 sec/batch)
2017-04-04 05:30:58.086479: step 1060, loss = 11.69 (125.3 examples/sec; 1.022 sec/batch)
2017-04-04 05:31:08.621495: step 1070, loss = 11.80 (122.4 examples/sec; 1.046 sec/batch)
2017-04-04 05:31:19.223195: step 1080, loss = 11.90 (122.0 examples/sec; 1.049 sec/batch)
2017-04-04 05:31:29.729634: step 1090, loss = 11.82 (118.5 examples/sec; 1.080 sec/batch)
2017-04-04 05:31:40.074492: step 1100, loss = 11.83 (125.9 examples/sec; 1.017 sec/batch)
2017-04-04 05:31:51.644365: step 1110, loss = 11.99 (122.6 examples/sec; 1.044 sec/batch)
2017-04-04 05:32:01.958052: step 1120, loss = 11.88 (125.3 examples/sec; 1.022 sec/batch)
2017-04-04 05:32:12.495486: step 1130, loss = 12.08 (123.6 examples/sec; 1.035 sec/batch)
2017-04-04 05:32:23.071452: step 1140, loss = 11.65 (124.4 examples/sec; 1.029 sec/batch)
2017-04-04 05:32:33.957861: step 1150, loss = 11.55 (119.9 examples/sec; 1.068 sec/batch)
2017-04-04 05:32:44.667571: step 1160, loss = 11.76 (123.4 examples/sec; 1.037 sec/batch)
2017-04-04 05:32:54.789895: step 1170, loss = 11.98 (120.8 examples/sec; 1.060 sec/batch)
2017-04-04 05:33:05.204314: step 1180, loss = 11.96 (124.8 examples/sec; 1.026 sec/batch)
2017-04-04 05:33:15.526104: step 1190, loss = 12.12 (122.9 examples/sec; 1.041 sec/batch)
2017-04-04 05:33:26.150454: step 1200, loss = 11.97 (122.0 examples/sec; 1.049 sec/batch)
2017-04-04 05:33:38.289104: step 1210, loss = 11.89 (119.1 examples/sec; 1.075 sec/batch)
2017-04-04 05:33:48.683475: step 1220, loss = 11.71 (130.8 examples/sec; 0.978 sec/batch)
2017-04-04 05:33:59.030989: step 1230, loss = 12.05 (126.0 examples/sec; 1.016 sec/batch)
2017-04-04 05:34:09.243093: step 1240, loss = 12.17 (126.3 examples/sec; 1.013 sec/batch)
2017-04-04 05:34:19.559850: step 1250, loss = 11.64 (121.7 examples/sec; 1.052 sec/batch)
2017-04-04 05:34:29.819548: step 1260, loss = 11.88 (124.7 examples/sec; 1.026 sec/batch)
2017-04-04 05:34:40.589704: step 1270, loss = 12.02 (117.4 examples/sec; 1.090 sec/batch)
2017-04-04 05:34:51.334319: step 1280, loss = 11.63 (118.7 examples/sec; 1.078 sec/batch)
2017-04-04 05:35:01.836818: step 1290, loss = 11.51 (122.5 examples/sec; 1.045 sec/batch)
2017-04-04 05:35:12.047668: step 1300, loss = 11.64 (129.4 examples/sec; 0.989 sec/batch)
2017-04-04 05:35:23.555694: step 1310, loss = 11.76 (123.6 examples/sec; 1.036 sec/batch)
2017-04-04 05:35:34.045233: step 1320, loss = 11.26 (121.9 examples/sec; 1.050 sec/batch)
2017-04-04 05:35:44.459576: step 1330, loss = 11.76 (118.2 examples/sec; 1.083 sec/batch)
2017-04-04 05:35:55.299985: step 1340, loss = 11.80 (119.0 examples/sec; 1.075 sec/batch)
2017-04-04 05:36:05.843623: step 1350, loss = 11.47 (125.6 examples/sec; 1.019 sec/batch)
2017-04-04 05:36:16.133102: step 1360, loss = 11.14 (126.2 examples/sec; 1.014 sec/batch)
2017-04-04 05:36:26.438481: step 1370, loss = 11.69 (123.3 examples/sec; 1.038 sec/batch)
2017-04-04 05:36:36.879372: step 1380, loss = 12.01 (124.1 examples/sec; 1.031 sec/batch)
2017-04-04 05:36:47.311985: step 1390, loss = 11.55 (127.2 examples/sec; 1.006 sec/batch)
2017-04-04 05:36:58.001272: step 1400, loss = 12.03 (125.8 examples/sec; 1.017 sec/batch)
2017-04-04 05:37:09.750187: step 1410, loss = 11.98 (122.5 examples/sec; 1.045 sec/batch)
2017-04-04 05:37:20.068018: step 1420, loss = 11.85 (125.0 examples/sec; 1.024 sec/batch)
2017-04-04 05:37:30.463047: step 1430, loss = 11.98 (117.5 examples/sec; 1.089 sec/batch)
2017-04-04 05:37:40.735707: step 1440, loss = 11.94 (123.1 examples/sec; 1.040 sec/batch)
2017-04-04 05:37:51.243778: step 1450, loss = 11.77 (125.8 examples/sec; 1.017 sec/batch)
2017-04-04 05:38:01.767895: step 1460, loss = 11.15 (123.4 examples/sec; 1.037 sec/batch)
2017-04-04 05:38:12.527834: step 1470, loss = 11.66 (112.8 examples/sec; 1.134 sec/batch)
2017-04-04 05:38:23.309330: step 1480, loss = 11.47 (124.5 examples/sec; 1.028 sec/batch)
2017-04-04 05:38:33.658667: step 1490, loss = 11.65 (121.0 examples/sec; 1.058 sec/batch)
2017-04-04 05:38:44.254050: step 1500, loss = 11.59 (116.7 examples/sec; 1.097 sec/batch)
2017-04-04 05:38:55.711682: step 1510, loss = 11.54 (122.6 examples/sec; 1.044 sec/batch)
2017-04-04 05:39:06.124076: step 1520, loss = 12.18 (117.2 examples/sec; 1.092 sec/batch)
2017-04-04 05:39:17.025554: step 1530, loss = 11.37 (110.7 examples/sec; 1.157 sec/batch)
2017-04-04 05:39:27.391853: step 1540, loss = 11.26 (125.4 examples/sec; 1.021 sec/batch)
2017-04-04 05:39:37.711910: step 1550, loss = 12.05 (124.9 examples/sec; 1.025 sec/batch)
2017-04-04 05:39:48.261665: step 1560, loss = 12.09 (124.9 examples/sec; 1.024 sec/batch)
2017-04-04 05:39:58.579557: step 1570, loss = 11.71 (128.7 examples/sec; 0.994 sec/batch)
2017-04-04 05:40:08.927043: step 1580, loss = 11.82 (121.5 examples/sec; 1.053 sec/batch)
2017-04-04 05:40:19.540243: step 1590, loss = 11.55 (120.1 examples/sec; 1.065 sec/batch)
2017-04-04 05:40:30.236302: step 1600, loss = 11.33 (122.2 examples/sec; 1.048 sec/batch)
2017-04-04 05:40:42.149713: step 1610, loss = 11.36 (121.9 examples/sec; 1.050 sec/batch)
2017-04-04 05:40:52.669828: step 1620, loss = 11.97 (115.3 examples/sec; 1.110 sec/batch)
2017-04-04 05:41:03.143548: step 1630, loss = 11.25 (121.1 examples/sec; 1.057 sec/batch)
2017-04-04 05:41:13.433839: step 1640, loss = 11.36 (124.5 examples/sec; 1.028 sec/batch)
2017-04-04 05:41:24.025010: step 1650, loss = 12.00 (125.6 examples/sec; 1.019 sec/batch)
2017-04-04 05:41:34.649277: step 1660, loss = 11.75 (121.1 examples/sec; 1.057 sec/batch)
2017-04-04 05:41:44.851858: step 1670, loss = 11.96 (129.8 examples/sec; 0.986 sec/batch)
2017-04-04 05:41:55.330722: step 1680, loss = 12.28 (120.1 examples/sec; 1.065 sec/batch)
2017-04-04 05:42:05.824395: step 1690, loss = 11.98 (125.5 examples/sec; 1.020 sec/batch)
2017-04-04 05:42:16.138431: step 1700, loss = 12.04 (122.7 examples/sec; 1.043 sec/batch)
2017-04-04 05:42:27.775513: step 1710, loss = 11.59 (126.7 examples/sec; 1.010 sec/batch)
2017-04-04 05:42:38.307311: step 1720, loss = 11.43 (127.1 examples/sec; 1.007 sec/batch)
2017-04-04 05:42:48.649595: step 1730, loss = 11.62 (124.9 examples/sec; 1.025 sec/batch)
2017-04-04 05:42:59.294918: step 1740, loss = 10.96 (112.6 examples/sec; 1.137 sec/batch)
2017-04-04 05:43:09.708069: step 1750, loss = 11.92 (116.6 examples/sec; 1.098 sec/batch)
2017-04-04 05:43:19.925476: step 1760, loss = 11.48 (124.7 examples/sec; 1.027 sec/batch)
2017-04-04 05:43:30.153196: step 1770, loss = 10.93 (125.0 examples/sec; 1.024 sec/batch)
2017-04-04 05:43:40.648274: step 1780, loss = 11.02 (114.8 examples/sec; 1.115 sec/batch)
2017-04-04 05:43:51.241350: step 1790, loss = 11.50 (109.2 examples/sec; 1.172 sec/batch)
2017-04-04 05:44:01.642752: step 1800, loss = 11.75 (114.1 examples/sec; 1.122 sec/batch)
2017-04-04 05:44:13.221627: step 1810, loss = 11.65 (116.0 examples/sec; 1.104 sec/batch)
2017-04-04 05:44:23.478283: step 1820, loss = 10.86 (123.2 examples/sec; 1.039 sec/batch)
2017-04-04 05:44:33.947365: step 1830, loss = 12.07 (120.5 examples/sec; 1.062 sec/batch)
2017-04-04 05:44:44.378157: step 1840, loss = 11.77 (122.6 examples/sec; 1.044 sec/batch)
2017-04-04 05:44:55.103101: step 1850, loss = 11.96 (121.9 examples/sec; 1.050 sec/batch)
2017-04-04 05:45:05.649642: step 1860, loss = 11.65 (123.9 examples/sec; 1.033 sec/batch)
2017-04-04 05:45:16.092418: step 1870, loss = 11.38 (121.1 examples/sec; 1.057 sec/batch)
2017-04-04 05:45:26.482075: step 1880, loss = 11.50 (123.0 examples/sec; 1.041 sec/batch)
2017-04-04 05:45:36.962010: step 1890, loss = 12.23 (121.2 examples/sec; 1.056 sec/batch)
2017-04-04 05:45:47.417748: step 1900, loss = 11.31 (124.8 examples/sec; 1.026 sec/batch)
2017-04-04 05:45:59.105705: step 1910, loss = 11.01 (126.6 examples/sec; 1.011 sec/batch)
2017-04-04 05:46:09.896404: step 1920, loss = 11.69 (123.8 examples/sec; 1.034 sec/batch)
2017-04-04 05:46:20.324874: step 1930, loss = 11.38 (127.0 examples/sec; 1.008 sec/batch)
2017-04-04 05:46:30.766157: step 1940, loss = 11.76 (120.2 examples/sec; 1.065 sec/batch)
2017-04-04 05:46:41.282860: step 1950, loss = 10.87 (124.2 examples/sec; 1.031 sec/batch)
2017-04-04 05:46:51.764000: step 1960, loss = 11.77 (122.9 examples/sec; 1.042 sec/batch)
2017-04-04 05:47:02.098181: step 1970, loss = 10.89 (126.4 examples/sec; 1.013 sec/batch)
2017-04-04 05:47:12.585452: step 1980, loss = 11.77 (127.7 examples/sec; 1.003 sec/batch)
2017-04-04 05:47:22.968674: step 1990, loss = 11.51 (123.5 examples/sec; 1.037 sec/batch)
2017-04-04 05:47:33.222048: step 2000, loss = 11.10 (124.6 examples/sec; 1.027 sec/batch)
2017-04-04 05:47:44.867451: step 2010, loss = 10.89 (126.0 examples/sec; 1.016 sec/batch)
2017-04-04 05:47:55.156373: step 2020, loss = 11.24 (122.9 examples/sec; 1.041 sec/batch)
2017-04-04 05:48:05.536529: step 2030, loss = 11.20 (122.1 examples/sec; 1.049 sec/batch)
2017-04-04 05:48:16.047332: step 2040, loss = 11.30 (117.6 examples/sec; 1.089 sec/batch)