2017-04-04 06:56:06.496953: step 0, loss = 12.95 (0.3 examples/sec; 25.119 sec/batch)
2017-04-04 06:56:35.768326: step 10, loss = 17.60 (28.8 examples/sec; 0.278 sec/batch)
2017-04-04 06:56:38.537798: step 20, loss = 16.62 (28.6 examples/sec; 0.279 sec/batch)
2017-04-04 06:56:41.337668: step 30, loss = 15.36 (28.5 examples/sec; 0.281 sec/batch)
2017-04-04 06:56:44.112765: step 40, loss = 14.57 (28.6 examples/sec; 0.280 sec/batch)
2017-04-04 06:56:46.894336: step 50, loss = 11.47 (28.7 examples/sec; 0.278 sec/batch)
2017-04-04 06:56:49.675990: step 60, loss = 13.96 (28.7 examples/sec; 0.279 sec/batch)
2017-04-04 06:56:52.463564: step 70, loss = 14.90 (28.9 examples/sec; 0.277 sec/batch)
2017-04-04 06:56:55.265875: step 80, loss = 13.45 (29.2 examples/sec; 0.274 sec/batch)
2017-04-04 06:56:58.051991: step 90, loss = 13.49 (29.1 examples/sec; 0.275 sec/batch)
2017-04-04 06:57:00.841929: step 100, loss = 13.74 (28.8 examples/sec; 0.278 sec/batch)
2017-04-04 06:57:04.066590: step 110, loss = 12.73 (28.9 examples/sec; 0.277 sec/batch)
2017-04-04 06:57:06.848597: step 120, loss = 12.87 (29.1 examples/sec; 0.275 sec/batch)
2017-04-04 06:57:09.624017: step 130, loss = 13.02 (28.6 examples/sec; 0.280 sec/batch)
2017-04-04 06:57:12.430006: step 140, loss = 12.72 (28.9 examples/sec; 0.277 sec/batch)
2017-04-04 06:57:15.204299: step 150, loss = 13.03 (28.3 examples/sec; 0.283 sec/batch)
2017-04-04 06:57:17.989107: step 160, loss = 13.36 (28.5 examples/sec; 0.281 sec/batch)
2017-04-04 06:57:20.769954: step 170, loss = 12.94 (29.4 examples/sec; 0.272 sec/batch)
2017-04-04 06:57:23.580847: step 180, loss = 13.09 (28.7 examples/sec; 0.279 sec/batch)
2017-04-04 06:57:26.356265: step 190, loss = 13.23 (28.4 examples/sec; 0.281 sec/batch)
2017-04-04 06:57:29.140364: step 200, loss = 12.67 (29.1 examples/sec; 0.275 sec/batch)