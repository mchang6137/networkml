2017-04-04 07:09:14.260167: step 10, loss = 13.40 (99.4 examples/sec; 0.644 sec/batch)
2017-04-04 07:09:20.710018: step 20, loss = 13.56 (96.4 examples/sec; 0.664 sec/batch)
2017-04-04 07:09:27.476481: step 30, loss = 13.34 (94.7 examples/sec; 0.676 sec/batch)
2017-04-04 07:09:34.352087: step 40, loss = 13.21 (88.5 examples/sec; 0.723 sec/batch)
2017-04-04 07:09:41.660096: step 50, loss = 14.20 (81.6 examples/sec; 0.784 sec/batch)
2017-04-04 07:09:48.645689: step 60, loss = 14.58 (92.1 examples/sec; 0.695 sec/batch)
2017-04-04 07:09:55.658073: step 70, loss = 12.73 (98.6 examples/sec; 0.649 sec/batch)
2017-04-04 07:10:02.221828: step 80, loss = 12.77 (93.3 examples/sec; 0.686 sec/batch)
2017-04-04 07:10:08.619466: step 90, loss = 12.68 (98.1 examples/sec; 0.652 sec/batch)
2017-04-04 07:10:15.295767: step 100, loss = 13.30 (104.9 examples/sec; 0.610 sec/batch)
2017-04-04 07:10:23.066374: step 110, loss = 12.99 (87.0 examples/sec; 0.735 sec/batch)
2017-04-04 07:10:38.354034: step 130, loss = 13.13 (87.6 examples/sec; 0.730 sec/batch)
2017-04-04 07:10:44.936473: step 140, loss = 12.79 (95.4 examples/sec; 0.671 sec/batch)
2017-04-04 07:10:51.596201: step 150, loss = 12.83 (94.5 examples/sec; 0.677 sec/batch)
2017-04-04 07:10:58.161295: step 160, loss = 12.90 (94.2 examples/sec; 0.679 sec/batch)
2017-04-04 07:11:05.249676: step 170, loss = 13.04 (87.1 examples/sec; 0.735 sec/batch)
2017-04-04 07:11:12.524293: step 180, loss = 12.88 (78.2 examples/sec; 0.818 sec/batch)
2017-04-04 07:11:20.125647: step 190, loss = 12.58 (80.8 examples/sec; 0.792 sec/batch)
2017-04-04 07:11:27.388358: step 200, loss = 12.71 (99.9 examples/sec; 0.641 sec/batch)
2017-04-04 07:11:34.697139: step 210, loss = 12.74 (97.2 examples/sec; 0.658 sec/batch)
2017-04-04 07:11:41.397707: step 220, loss = 12.99 (90.7 examples/sec; 0.706 sec/batch)
2017-04-04 07:11:48.072861: step 230, loss = 12.49 (94.7 examples/sec; 0.676 sec/batch)
2017-04-04 07:11:54.980735: step 240, loss = 12.58 (85.0 examples/sec; 0.753 sec/batch)
2017-04-04 07:12:02.338526: step 250, loss = 12.27 (80.5 examples/sec; 0.795 sec/batch)
2017-04-04 07:12:09.972220: step 260, loss = 12.61 (89.5 examples/sec; 0.715 sec/batch)
2017-04-04 07:12:16.958368: step 270, loss = 12.69 (96.4 examples/sec; 0.664 sec/batch)
2017-04-04 07:12:23.543641: step 280, loss = 12.78 (93.0 examples/sec; 0.688 sec/batch)
2017-04-04 07:12:30.277370: step 290, loss = 12.23 (93.9 examples/sec; 0.681 sec/batch)
2017-04-04 07:12:37.036302: step 300, loss = 12.82 (98.2 examples/sec; 0.651 sec/batch)
2017-04-04 07:12:44.872395: step 310, loss = 12.24 (88.8 examples/sec; 0.721 sec/batch)
2017-04-04 07:12:52.247012: step 320, loss = 12.45 (84.7 examples/sec; 0.756 sec/batch)
2017-04-04 07:12:59.332705: step 330, loss = 12.95 (99.4 examples/sec; 0.644 sec/batch)
2017-04-04 07:13:06.169539: step 340, loss = 12.54 (93.9 examples/sec; 0.682 sec/batch)
2017-04-04 07:13:12.789641: step 350, loss = 12.74 (102.4 examples/sec; 0.625 sec/batch)
2017-04-04 07:13:19.484141: step 360, loss = 12.36 (95.8 examples/sec; 0.668 sec/batch)
2017-04-04 07:13:26.374622: step 370, loss = 12.69 (91.7 examples/sec; 0.698 sec/batch)
2017-04-04 07:13:33.467757: step 380, loss = 12.89 (83.3 examples/sec; 0.769 sec/batch)
2017-04-04 07:13:40.828746: step 390, loss = 13.01 (92.2 examples/sec; 0.694 sec/batch)
2017-04-04 07:13:47.778329: step 400, loss = 12.55 (96.1 examples/sec; 0.666 sec/batch)
2017-04-04 07:13:55.206907: step 410, loss = 12.61 (94.6 examples/sec; 0.677 sec/batch)
2017-04-04 07:14:01.894810: step 420, loss = 12.21 (97.0 examples/sec; 0.660 sec/batch)
2017-04-04 07:14:08.627137: step 430, loss = 12.34 (95.3 examples/sec; 0.671 sec/batch)
2017-04-04 07:14:15.565397: step 440, loss = 12.51 (88.5 examples/sec; 0.724 sec/batch)
2017-04-04 07:14:22.999431: step 450, loss = 12.59 (84.4 examples/sec; 0.758 sec/batch)
2017-04-04 07:14:30.311141: step 460, loss = 12.37 (86.4 examples/sec; 0.741 sec/batch)
2017-04-04 07:14:37.306682: step 470, loss = 12.62 (94.5 examples/sec; 0.677 sec/batch)
2017-04-04 07:14:43.939417: step 480, loss = 12.66 (95.9 examples/sec; 0.668 sec/batch)
2017-04-04 07:14:50.589785: step 490, loss = 12.40 (98.0 examples/sec; 0.653 sec/batch)
2017-04-04 07:14:57.429648: step 500, loss = 12.22 (97.3 examples/sec; 0.658 sec/batch)
2017-04-04 07:15:05.055666: step 510, loss = 12.96 (93.0 examples/sec; 0.688 sec/batch)
2017-04-04 07:15:12.277559: step 520, loss = 12.86 (92.0 examples/sec; 0.695 sec/batch)
2017-04-04 07:15:19.136601: step 530, loss = 12.75 (99.2 examples/sec; 0.645 sec/batch)
2017-04-04 07:15:25.889176: step 540, loss = 12.55 (95.7 examples/sec; 0.669 sec/batch)
2017-04-04 07:15:32.509399: step 550, loss = 12.54 (95.4 examples/sec; 0.671 sec/batch)
2017-04-04 07:15:39.293110: step 560, loss = 12.38 (91.0 examples/sec; 0.703 sec/batch)
2017-04-04 07:15:46.259670: step 570, loss = 12.53 (91.1 examples/sec; 0.702 sec/batch)
2017-04-04 07:15:53.522698: step 580, loss = 12.83 (83.4 examples/sec; 0.767 sec/batch)
2017-04-04 07:16:00.701280: step 590, loss = 12.54 (98.5 examples/sec; 0.650 sec/batch)
2017-04-04 07:16:07.571069: step 600, loss = 12.68 (92.3 examples/sec; 0.693 sec/batch)
2017-04-04 07:16:15.024885: step 610, loss = 12.52 (100.0 examples/sec; 0.640 sec/batch)
2017-04-04 07:16:21.857606: step 620, loss = 12.29 (90.9 examples/sec; 0.704 sec/batch)
2017-04-04 07:16:28.716717: step 630, loss = 12.86 (85.6 examples/sec; 0.747 sec/batch)
2017-04-04 07:16:35.795128: step 640, loss = 12.63 (81.6 examples/sec; 0.784 sec/batch)
2017-04-04 07:16:43.418603: step 650, loss = 12.52 (87.5 examples/sec; 0.732 sec/batch)
2017-04-04 07:16:50.243404: step 660, loss = 12.52 (97.6 examples/sec; 0.656 sec/batch)
2017-04-04 07:16:56.919676: step 670, loss = 12.56 (101.3 examples/sec; 0.632 sec/batch)
2017-04-04 07:17:03.542533: step 680, loss = 12.74 (95.5 examples/sec; 0.671 sec/batch)
2017-04-04 07:17:10.153905: step 690, loss = 12.49 (94.8 examples/sec; 0.675 sec/batch)
2017-04-04 07:17:16.963211: step 700, loss = 12.47 (93.7 examples/sec; 0.683 sec/batch)
2017-04-04 07:17:24.597395: step 710, loss = 12.80 (92.7 examples/sec; 0.690 sec/batch)
2017-04-04 07:17:31.457531: step 720, loss = 12.29 (91.7 examples/sec; 0.698 sec/batch)
2017-04-04 07:17:38.184490: step 730, loss = 12.55 (91.7 examples/sec; 0.698 sec/batch)
2017-04-04 07:17:44.880129: step 740, loss = 12.21 (93.5 examples/sec; 0.685 sec/batch)
2017-04-04 07:17:51.637966: step 750, loss = 12.22 (86.8 examples/sec; 0.738 sec/batch)
2017-04-04 07:17:58.522432: step 760, loss = 12.21 (93.3 examples/sec; 0.686 sec/batch)
2017-04-04 07:18:05.571363: step 770, loss = 12.40 (88.8 examples/sec; 0.720 sec/batch)
2017-04-04 07:18:12.511099: step 780, loss = 12.43 (91.1 examples/sec; 0.703 sec/batch)
2017-04-04 07:18:19.248817: step 790, loss = 12.16 (90.9 examples/sec; 0.704 sec/batch)
2017-04-04 07:18:25.956770: step 800, loss = 12.47 (94.7 examples/sec; 0.675 sec/batch)
2017-04-04 07:18:33.432764: step 810, loss = 12.45 (98.3 examples/sec; 0.651 sec/batch)
2017-04-04 07:18:40.085149: step 820, loss = 11.98 (99.5 examples/sec; 0.643 sec/batch)
2017-04-04 07:18:47.048844: step 830, loss = 12.59 (94.7 examples/sec; 0.676 sec/batch)
2017-04-04 07:18:53.845516: step 840, loss = 12.37 (92.1 examples/sec; 0.695 sec/batch)
2017-04-04 07:19:00.830688: step 850, loss = 12.41 (92.2 examples/sec; 0.694 sec/batch)
2017-04-04 07:19:07.724307: step 860, loss = 12.40 (98.2 examples/sec; 0.652 sec/batch)
2017-04-04 07:19:14.437366: step 870, loss = 12.53 (98.3 examples/sec; 0.651 sec/batch)
2017-04-04 07:19:21.190657: step 880, loss = 11.98 (94.0 examples/sec; 0.681 sec/batch)~