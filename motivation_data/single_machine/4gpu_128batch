2017-04-04 06:03:25.892031: step 10, loss = 12.95 (81.5 examples/sec; 1.571 sec/batch)
2017-04-04 06:03:41.714044: step 20, loss = 12.81 (80.4 examples/sec; 1.591 sec/batch)
2017-04-04 06:03:57.577180: step 30, loss = 13.09 (80.5 examples/sec; 1.590 sec/batch)
2017-04-04 06:04:13.476347: step 40, loss = 13.35 (80.8 examples/sec; 1.585 sec/batch)
2017-04-04 06:04:29.410985: step 50, loss = 13.20 (79.9 examples/sec; 1.603 sec/batch)
2017-04-04 06:04:45.361067: step 60, loss = 13.04 (80.3 examples/sec; 1.594 sec/batch)
2017-04-04 06:05:01.719659: step 70, loss = 12.93 (77.1 examples/sec; 1.660 sec/batch)
2017-04-04 06:05:17.897053: step 80, loss = 12.92 (77.0 examples/sec; 1.663 sec/batch)
2017-04-04 06:05:34.383272: step 90, loss = 12.83 (77.0 examples/sec; 1.663 sec/batch)
2017-04-04 06:05:50.674923: step 100, loss = 13.07 (80.5 examples/sec; 1.591 sec/batch)
2017-04-04 06:06:08.456492: step 110, loss = 12.86 (80.7 examples/sec; 1.586 sec/batch)
2017-04-04 06:06:24.319491: step 120, loss = 12.84 (80.9 examples/sec; 1.583 sec/batch)
2017-04-04 06:06:40.236513: step 130, loss = 12.56 (77.6 examples/sec; 1.649 sec/batch)
2017-04-04 06:06:56.139357: step 140, loss = 12.73 (80.4 examples/sec; 1.593 sec/batch)
2017-04-04 06:07:12.169881: step 150, loss = 12.82 (80.0 examples/sec; 1.601 sec/batch)
2017-04-04 06:07:28.512248: step 160, loss = 12.51 (76.8 examples/sec; 1.668 sec/batch)
2017-04-04 06:07:45.180210: step 170, loss = 12.76 (76.8 examples/sec; 1.666 sec/batch)
2017-04-04 06:08:01.709579: step 180, loss = 12.55 (77.1 examples/sec; 1.661 sec/batch)
2017-04-04 06:08:18.338719: step 190, loss = 12.53 (76.9 examples/sec; 1.664 sec/batch)
2017-04-04 06:08:34.655929: step 200, loss = 12.59 (79.9 examples/sec; 1.602 sec/batch)
2017-04-04 06:08:52.626664: step 210, loss = 12.49 (77.2 examples/sec; 1.658 sec/batch)
2017-04-04 06:09:09.204385: step 220, loss = 12.36 (76.6 examples/sec; 1.672 sec/batch)
2017-04-04 06:09:25.353413: step 230, loss = 12.27 (80.4 examples/sec; 1.592 sec/batch)
2017-04-04 06:09:41.858432: step 240, loss = 12.34 (77.0 examples/sec; 1.663 sec/batch)
2017-04-04 06:09:58.247647: step 250, loss = 12.38 (76.7 examples/sec; 1.669 sec/batch)
2017-04-04 06:10:14.597413: step 260, loss = 12.53 (79.8 examples/sec; 1.604 sec/batch)
2017-04-04 06:10:30.673966: step 270, loss = 12.49 (80.3 examples/sec; 1.593 sec/batch)
2017-04-04 06:10:46.923430: step 280, loss = 12.32 (76.6 examples/sec; 1.671 sec/batch)
2017-04-04 06:11:03.226730: step 290, loss = 12.46 (80.4 examples/sec; 1.592 sec/batch)
2017-04-04 06:11:19.936656: step 300, loss = 12.36 (76.5 examples/sec; 1.674 sec/batch)
2017-04-04 06:11:38.194628: step 310, loss = 12.30 (77.0 examples/sec; 1.662 sec/batch)
2017-04-04 06:11:54.827891: step 320, loss = 12.42 (76.7 examples/sec; 1.668 sec/batch)
2017-04-04 06:12:11.245749: step 330, loss = 12.47 (76.3 examples/sec; 1.677 sec/batch)
2017-04-04 06:12:27.758312: step 340, loss = 11.95 (77.3 examples/sec; 1.656 sec/batch)
2017-04-04 06:12:43.941027: step 350, loss = 12.37 (80.1 examples/sec; 1.597 sec/batch)
2017-04-04 06:13:00.250803: step 360, loss = 12.24 (77.0 examples/sec; 1.661 sec/batch)
2017-04-04 06:13:16.904684: step 370, loss = 12.24 (77.2 examples/sec; 1.658 sec/batch)
2017-04-04 06:13:33.084107: step 380, loss = 12.27 (80.2 examples/sec; 1.595 sec/batch)
2017-04-04 06:13:49.361516: step 390, loss = 12.25 (76.3 examples/sec; 1.678 sec/batch)
2017-04-04 06:14:05.999689: step 400, loss = 12.87 (76.5 examples/sec; 1.673 sec/batch)
2017-04-04 06:14:23.892215: step 410, loss = 12.39 (76.9 examples/sec; 1.664 sec/batch)
2017-04-04 06:14:40.477000: step 420, loss = 12.36 (76.6 examples/sec; 1.670 sec/batch)
2017-04-04 06:14:57.160925: step 430, loss = 12.45 (77.2 examples/sec; 1.659 sec/batch)
2017-04-04 06:15:13.824476: step 440, loss = 12.07 (77.3 examples/sec; 1.657 sec/batch)
2017-04-04 06:15:30.421057: step 450, loss = 12.37 (76.1 examples/sec; 1.681 sec/batch)
2017-04-04 06:15:47.054299: step 460, loss = 12.41 (76.4 examples/sec; 1.675 sec/batch)
2017-04-04 06:16:03.646408: step 470, loss = 12.35 (80.5 examples/sec; 1.590 sec/batch)
2017-04-04 06:16:20.193119: step 480, loss = 12.29 (76.4 examples/sec; 1.675 sec/batch)
2017-04-04 06:16:36.463419: step 490, loss = 12.15 (76.7 examples/sec; 1.668 sec/batch)
2017-04-04 06:16:52.780048: step 500, loss = 12.24 (77.1 examples/sec; 1.660 sec/batch)
2017-04-04 06:17:10.944587: step 510, loss = 12.40 (77.2 examples/sec; 1.658 sec/batch)
2017-04-04 06:17:27.327256: step 520, loss = 12.27 (80.0 examples/sec; 1.600 sec/batch)
2017-04-04 06:17:43.960090: step 530, loss = 12.21 (76.9 examples/sec; 1.665 sec/batch)
2017-04-04 06:18:00.338037: step 540, loss = 12.33 (80.3 examples/sec; 1.594 sec/batch)
2017-04-04 06:18:17.005339: step 550, loss = 12.25 (76.3 examples/sec; 1.677 sec/batch)
2017-04-04 06:18:33.561709: step 560, loss = 12.05 (80.3 examples/sec; 1.595 sec/batch)
2017-04-04 06:18:50.040156: step 570, loss = 12.16 (76.6 examples/sec; 1.672 sec/batch)
2017-04-04 06:19:06.365036: step 580, loss = 12.02 (79.9 examples/sec; 1.603 sec/batch)
2017-04-04 06:19:22.721896: step 590, loss = 12.25 (79.7 examples/sec; 1.605 sec/batch)
2017-04-04 06:19:39.181941: step 600, loss = 12.21 (76.9 examples/sec; 1.664 sec/batch)
2017-04-04 06:19:57.621270: step 610, loss = 12.12 (76.5 examples/sec; 1.673 sec/batch)
2017-04-04 06:20:14.026651: step 620, loss = 12.11 (76.5 examples/sec; 1.672 sec/batch)
2017-04-04 06:20:30.416610: step 630, loss = 12.30 (76.9 examples/sec; 1.664 sec/batch)
2017-04-04 06:20:47.067306: step 640, loss = 12.01 (76.7 examples/sec; 1.669 sec/batch)
2017-04-04 06:21:03.382118: step 650, loss = 12.05 (80.1 examples/sec; 1.598 sec/batch)
2017-04-04 06:21:19.957360: step 660, loss = 12.14 (76.7 examples/sec; 1.668 sec/batch)
2017-04-04 06:21:36.613230: step 670, loss = 12.08 (76.6 examples/sec; 1.671 sec/batch)
2017-04-04 06:21:52.841373: step 680, loss = 12.08 (80.3 examples/sec; 1.595 sec/batch)
2017-04-04 06:22:09.091539: step 690, loss = 12.08 (80.0 examples/sec; 1.601 sec/batch)
2017-04-04 06:22:25.231161: step 700, loss = 12.30 (79.8 examples/sec; 1.604 sec/batch)
2017-04-04 06:22:43.442528: step 710, loss = 12.33 (76.4 examples/sec; 1.676 sec/batch)
2017-04-04 06:22:59.683482: step 720, loss = 12.31 (76.4 examples/sec; 1.675 sec/batch)
2017-04-04 06:23:16.070345: step 730, loss = 12.17 (76.7 examples/sec; 1.669 sec/batch)
2017-04-04 06:23:32.595951: step 740, loss = 12.25 (76.7 examples/sec; 1.669 sec/batch)
2017-04-04 06:23:48.855472: step 750, loss = 12.13 (80.5 examples/sec; 1.589 sec/batch)
2017-04-04 06:24:05.242143: step 760, loss = 12.14 (76.8 examples/sec; 1.666 sec/batch)
2017-04-04 06:24:21.552924: step 770, loss = 12.13 (80.0 examples/sec; 1.600 sec/batch)
2017-04-04 06:24:37.911568: step 780, loss = 11.79 (80.0 examples/sec; 1.600 sec/batch)
2017-04-04 06:24:54.174682: step 790, loss = 11.93 (80.2 examples/sec; 1.596 sec/batch)
2017-04-04 06:25:10.811911: step 800, loss = 12.08 (77.2 examples/sec; 1.659 sec/batch)~