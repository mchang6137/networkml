2017-04-04 04:31:37.925663: step 0, loss = 13.09 (2.8 examples/sec; 138.511 sec/batch)
2017-04-04 04:32:33.153762: step 10, loss = 12.90 (153.4 examples/sec; 2.503 sec/batch)
2017-04-04 04:32:58.885612: step 20, loss = 12.78 (150.7 examples/sec; 2.548 sec/batch)
2017-04-04 04:33:24.390901: step 30, loss = 12.69 (153.1 examples/sec; 2.509 sec/batch)
2017-04-04 04:33:49.703954: step 40, loss = 12.82 (152.5 examples/sec; 2.518 sec/batch)
2017-04-04 04:34:15.187194: step 50, loss = 12.82 (149.2 examples/sec; 2.574 sec/batch)
2017-04-04 04:34:41.229571: step 60, loss = 12.87 (150.2 examples/sec; 2.557 sec/batch)
2017-04-04 04:35:06.812007: step 70, loss = 12.74 (148.7 examples/sec; 2.583 sec/batch)
2017-04-04 04:35:32.421327: step 80, loss = 12.68 (148.2 examples/sec; 2.592 sec/batch)
2017-04-04 04:35:57.890531: step 90, loss = 12.66 (152.0 examples/sec; 2.526 sec/batch)
2017-04-04 04:36:23.361977: step 100, loss = 12.52 (152.9 examples/sec; 2.511 sec/batch)
2017-04-04 04:36:51.708105: step 110, loss = 12.59 (152.7 examples/sec; 2.515 sec/batch)
2017-04-04 04:37:17.172833: step 120, loss = 12.55 (150.1 examples/sec; 2.558 sec/batch)
2017-04-04 04:37:42.621018: step 130, loss = 12.23 (149.5 examples/sec; 2.569 sec/batch)
2017-04-04 04:38:08.061078: step 140, loss = 12.56 (151.3 examples/sec; 2.537 sec/batch)
2017-04-04 04:38:33.626772: step 150, loss = 12.71 (151.6 examples/sec; 2.533 sec/batch)
2017-04-04 04:38:58.945687: step 160, loss = 12.58 (152.6 examples/sec; 2.516 sec/batch)
2017-04-04 04:39:24.288555: step 170, loss = 12.69 (150.3 examples/sec; 2.556 sec/batch)
2017-04-04 04:39:49.711364: step 180, loss = 12.43 (150.2 examples/sec; 2.557 sec/batch)
2017-04-04 04:40:15.048799: step 190, loss = 12.68 (152.5 examples/sec; 2.518 sec/batch)
2017-04-04 04:40:40.646851: step 200, loss = 12.37 (149.4 examples/sec; 2.570 sec/batch)
2017-04-04 04:41:09.004521: step 210, loss = 12.35 (152.8 examples/sec; 2.512 sec/batch)
2017-04-04 04:41:34.342036: step 220, loss = 12.57 (151.3 examples/sec; 2.538 sec/batch)
2017-04-04 04:41:59.703915: step 230, loss = 12.26 (151.9 examples/sec; 2.528 sec/batch)
2017-04-04 04:42:24.987839: step 240, loss = 12.41 (150.0 examples/sec; 2.559 sec/batch)
2017-04-04 04:42:50.423712: step 250, loss = 12.39 (150.2 examples/sec; 2.556 sec/batch)
2017-04-04 04:43:16.028585: step 260, loss = 12.61 (151.2 examples/sec; 2.539 sec/batch)
2017-04-04 04:43:41.536157: step 270, loss = 12.22 (150.8 examples/sec; 2.547 sec/batch)
2017-04-04 04:44:06.989968: step 280, loss = 12.22 (151.5 examples/sec; 2.535 sec/batch)
2017-04-04 04:44:32.321848: step 290, loss = 12.23 (152.7 examples/sec; 2.515 sec/batch)
2017-04-04 04:44:57.734171: step 300, loss = 12.04 (153.2 examples/sec; 2.506 sec/batch)
2017-04-04 04:45:26.199177: step 310, loss = 12.29 (150.3 examples/sec; 2.556 sec/batch)
2017-04-04 04:45:51.600118: step 320, loss = 12.12 (151.4 examples/sec; 2.536 sec/batch)
2017-04-04 04:46:17.055012: step 330, loss = 12.48 (150.3 examples/sec; 2.555 sec/batch)
2017-04-04 04:46:42.666857: step 340, loss = 11.80 (150.8 examples/sec; 2.547 sec/batch)
2017-04-04 04:47:08.087756: step 350, loss = 12.03 (151.2 examples/sec; 2.540 sec/batch)
2017-04-04 04:47:33.492646: step 360, loss = 12.31 (149.1 examples/sec; 2.575 sec/batch)
2017-04-04 04:47:59.301246: step 370, loss = 11.67 (129.6 examples/sec; 2.963 sec/batch)
2017-04-04 04:48:24.716965: step 380, loss = 12.02 (149.2 examples/sec; 2.573 sec/batch)
2017-04-04 04:48:50.175344: step 390, loss = 12.24 (150.8 examples/sec; 2.547 sec/batch)
2017-04-04 04:49:15.605735: step 400, loss = 12.21 (151.9 examples/sec; 2.528 sec/batch)
2017-04-04 04:49:44.111994: step 410, loss = 12.05 (152.6 examples/sec; 2.516 sec/batch)
2017-04-04 04:50:09.461016: step 420, loss = 11.49 (150.3 examples/sec; 2.555 sec/batch)
2017-04-04 04:50:34.858547: step 430, loss = 11.93 (150.0 examples/sec; 2.560 sec/batch)
2017-04-04 04:51:00.609017: step 440, loss = 12.28 (153.7 examples/sec; 2.498 sec/batch)
2017-04-04 04:51:26.085841: step 450, loss = 12.12 (150.2 examples/sec; 2.556 sec/batch)
2017-04-04 04:51:51.430001: step 460, loss = 11.74 (147.7 examples/sec; 2.601 sec/batch)
2017-04-04 04:52:16.848165: step 470, loss = 11.97 (150.5 examples/sec; 2.551 sec/batch)
2017-04-04 04:52:42.208147: step 480, loss = 11.97 (151.3 examples/sec; 2.539 sec/batch)
2017-04-04 04:53:07.573668: step 490, loss = 11.83 (148.0 examples/sec; 2.595 sec/batch)
2017-04-04 04:53:32.963669: step 500, loss = 11.87 (152.5 examples/sec; 2.518 sec/batch)
2017-04-04 04:54:01.602660: step 510, loss = 12.03 (148.5 examples/sec; 2.585 sec/batch)
2017-04-04 04:54:27.149318: step 520, loss = 12.10 (150.5 examples/sec; 2.551 sec/batch)
2017-04-04 04:54:52.650728: step 530, loss = 11.62 (149.6 examples/sec; 2.566 sec/batch)
2017-04-04 04:55:18.001249: step 540, loss = 11.85 (152.3 examples/sec; 2.521 sec/batch)
2017-04-04 04:55:43.525111: step 550, loss = 11.88 (152.6 examples/sec; 2.516 sec/batch)
2017-04-04 04:56:08.902026: step 560, loss = 12.12 (148.3 examples/sec; 2.589 sec/batch)
2017-04-04 04:56:34.459773: step 570, loss = 12.01 (150.1 examples/sec; 2.558 sec/batch)
2017-04-04 04:57:00.066101: step 580, loss = 11.28 (149.7 examples/sec; 2.565 sec/batch)
2017-04-04 04:57:25.577769: step 590, loss = 11.99 (147.9 examples/sec; 2.596 sec/batch)
2017-04-04 04:57:51.013332: step 600, loss = 11.49 (152.8 examples/sec; 2.514 sec/batch)
2017-04-04 04:58:19.881807: step 610, loss = 11.47 (149.3 examples/sec; 2.572 sec/batch)
2017-04-04 04:58:45.414518: step 620, loss = 11.84 (151.9 examples/sec; 2.529 sec/batch)
2017-04-04 04:59:10.860572: step 630, loss = 11.81 (152.1 examples/sec; 2.524 sec/batch)
2017-04-04 04:59:36.389292: step 640, loss = 11.72 (151.0 examples/sec; 2.543 sec/batch)
2017-04-04 05:00:01.821189: step 650, loss = 11.40 (151.9 examples/sec; 2.528 sec/batch)
2017-04-04 05:00:27.686574: step 660, loss = 11.67 (150.2 examples/sec; 2.557 sec/batch)
2017-04-04 05:00:53.334951: step 670, loss = 11.78 (151.3 examples/sec; 2.538 sec/batch)
2017-04-04 05:01:18.866040: step 680, loss = 11.73 (151.4 examples/sec; 2.537 sec/batch)
2017-04-04 05:01:44.272000: step 690, loss = 11.55 (150.1 examples/sec; 2.559 sec/batch)
2017-04-04 05:02:09.875047: step 700, loss = 11.54 (147.1 examples/sec; 2.611 sec/batch)
2017-04-04 05:02:38.811056: step 710, loss = 11.50 (151.8 examples/sec; 2.529 sec/batch)
2017-04-04 05:03:04.276859: step 720, loss = 11.62 (150.8 examples/sec; 2.547 sec/batch)
2017-04-04 05:03:29.706519: step 730, loss = 11.66 (151.4 examples/sec; 2.537 sec/batch)
2017-04-04 05:03:55.138325: step 740, loss = 11.56 (153.0 examples/sec; 2.509 sec/batch)
2017-04-04 05:04:20.500906: step 750, loss = 11.47 (151.3 examples/sec; 2.537 sec/batch)
2017-04-04 05:04:45.986111: step 760, loss = 11.91 (150.9 examples/sec; 2.545 sec/batch)
2017-04-04 05:05:12.045386: step 770, loss = 11.34 (151.8 examples/sec; 2.530 sec/batch)
2017-04-04 05:05:37.590094: step 780, loss = 11.36 (150.9 examples/sec; 2.544 sec/batch)
2017-04-04 05:06:03.038140: step 790, loss = 11.42 (151.5 examples/sec; 2.535 sec/batch)
2017-04-04 05:06:28.547187: step 800, loss = 11.73 (148.9 examples/sec; 2.579 sec/batch)