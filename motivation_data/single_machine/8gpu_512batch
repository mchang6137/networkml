2017-04-04 03:30:21.629640: step 0, loss = 13.05 (2.9 examples/sec; 178.920 sec/batch)
2017-04-04 03:31:25.218321: step 10, loss = 12.92 (151.9 examples/sec; 3.371 sec/batch)
2017-04-04 03:31:59.195012: step 20, loss = 12.84 (151.6 examples/sec; 3.378 sec/batch)
2017-04-04 03:32:33.242593: step 30, loss = 12.72 (149.3 examples/sec; 3.430 sec/batch)
2017-04-04 03:33:07.032732: step 40, loss = 12.71 (153.7 examples/sec; 3.330 sec/batch)
2017-04-04 03:33:40.654748: step 50, loss = 12.72 (154.2 examples/sec; 3.320 sec/batch)
2017-04-04 03:34:14.512114: step 60, loss = 12.84 (149.9 examples/sec; 3.415 sec/batch)
2017-04-04 03:34:48.004748: step 70, loss = 12.67 (152.2 examples/sec; 3.365 sec/batch)
2017-04-04 03:35:21.504136: step 80, loss = 12.62 (152.0 examples/sec; 3.368 sec/batch)
2017-04-04 03:35:55.167884: step 90, loss = 12.51 (151.7 examples/sec; 3.376 sec/batch)
2017-04-04 03:36:29.036519: step 100, loss = 12.57 (150.1 examples/sec; 3.410 sec/batch)
2017-04-04 03:37:07.275127: step 110, loss = 12.52 (145.5 examples/sec; 3.518 sec/batch)
2017-04-04 03:37:41.126309: step 120, loss = 12.63 (150.7 examples/sec; 3.399 sec/batch)
2017-04-04 03:38:14.893805: step 130, loss = 12.57 (152.6 examples/sec; 3.355 sec/batch)
2017-04-04 03:38:48.318356: step 140, loss = 12.55 (153.1 examples/sec; 3.345 sec/batch)
2017-04-04 03:39:21.981561: step 150, loss = 12.45 (152.5 examples/sec; 3.358 sec/batch)
2017-04-04 03:39:55.728121: step 160, loss = 12.61 (155.0 examples/sec; 3.303 sec/batch)
2017-04-04 03:40:29.703690: step 170, loss = 12.59 (152.4 examples/sec; 3.360 sec/batch)
2017-04-04 03:41:04.141734: step 180, loss = 12.67 (147.2 examples/sec; 3.477 sec/batch)
2017-04-04 03:41:38.216454: step 190, loss = 12.64 (151.0 examples/sec; 3.391 sec/batch)
2017-04-04 03:42:11.784376: step 200, loss = 12.30 (154.0 examples/sec; 3.324 sec/batch)
2017-04-04 03:42:49.493916: step 210, loss = 12.18 (150.9 examples/sec; 3.393 sec/batch)
2017-04-04 03:43:23.241180: step 220, loss = 12.35 (153.1 examples/sec; 3.343 sec/batch)
2017-04-04 03:43:57.177710: step 230, loss = 12.57 (151.3 examples/sec; 3.385 sec/batch)
2017-04-04 03:44:31.135676: step 240, loss = 12.34 (151.2 examples/sec; 3.387 sec/batch)
2017-04-04 03:45:04.898471: step 250, loss = 12.05 (151.6 examples/sec; 3.376 sec/batch)
2017-04-04 03:45:38.465264: step 260, loss = 12.27 (153.7 examples/sec; 3.331 sec/batch)
2017-04-04 03:46:11.913996: step 270, loss = 12.09 (152.4 examples/sec; 3.359 sec/batch)
2017-04-04 03:46:45.379726: step 280, loss = 12.14 (155.2 examples/sec; 3.298 sec/batch)
2017-04-04 03:47:19.479503: step 290, loss = 12.24 (154.2 examples/sec; 3.321 sec/batch)
2017-04-04 03:47:53.297178: step 300, loss = 11.98 (150.8 examples/sec; 3.395 sec/batch)
2017-04-04 03:48:31.459364: step 310, loss = 12.12 (151.2 examples/sec; 3.386 sec/batch)
2017-04-04 03:49:05.223125: step 320, loss = 12.05 (153.0 examples/sec; 3.346 sec/batch)
2017-04-04 03:49:39.287608: step 330, loss = 12.13 (154.0 examples/sec; 3.325 sec/batch)
2017-04-04 03:50:12.772965: step 340, loss = 11.98 (152.5 examples/sec; 3.358 sec/batch)
2017-04-04 03:50:46.527985: step 350, loss = 12.02 (154.3 examples/sec; 3.319 sec/batch)
2017-04-04 03:51:20.513365: step 360, loss = 12.05 (151.8 examples/sec; 3.372 sec/batch)
2017-04-04 03:51:54.245216: step 370, loss = 11.98 (150.8 examples/sec; 3.396 sec/batch)
2017-04-04 03:52:28.264211: step 380, loss = 11.77 (152.6 examples/sec; 3.355 sec/batch)
2017-04-04 03:53:01.924183: step 390, loss = 11.70 (149.0 examples/sec; 3.437 sec/batch)
2017-04-04 03:53:35.502694: step 400, loss = 11.81 (155.1 examples/sec; 3.302 sec/batch)
2017-04-04 03:54:13.280209: step 410, loss = 12.23 (151.7 examples/sec; 3.375 sec/batch)
2017-04-04 03:54:46.735210: step 420, loss = 11.93 (151.7 examples/sec; 3.375 sec/batch)
2017-04-04 03:55:20.521037: step 430, loss = 11.82 (150.5 examples/sec; 3.402 sec/batch)
2017-04-04 03:55:54.254540: step 440, loss = 11.80 (151.1 examples/sec; 3.388 sec/batch)
2017-04-04 03:56:27.902254: step 450, loss = 11.82 (153.9 examples/sec; 3.326 sec/batch)
2017-04-04 03:57:01.402743: step 460, loss = 11.85 (154.7 examples/sec; 3.309 sec/batch)
2017-04-04 03:57:34.842056: step 470, loss = 12.05 (148.6 examples/sec; 3.445 sec/batch)
2017-04-04 03:58:08.534981: step 480, loss = 12.04 (153.5 examples/sec; 3.335 sec/batch)
2017-04-04 03:58:42.165653: step 490, loss = 11.86 (155.1 examples/sec; 3.300 sec/batch)
2017-04-04 03:59:15.966339: step 500, loss = 11.65 (150.3 examples/sec; 3.406 sec/batch)
2017-04-04 03:59:54.363068: step 510, loss = 11.70 (152.7 examples/sec; 3.354 sec/batch)
2017-04-04 04:00:27.840175: step 520, loss = 11.86 (154.4 examples/sec; 3.316 sec/batch)
2017-04-04 04:01:01.346445: step 530, loss = 11.64 (153.1 examples/sec; 3.345 sec/batch)
2017-04-04 04:01:34.982258: step 540, loss = 11.56 (143.9 examples/sec; 3.557 sec/batch)
2017-04-04 04:02:08.304219: step 550, loss = 11.67 (154.3 examples/sec; 3.319 sec/batch)
2017-04-04 04:02:42.114124: step 560, loss = 11.47 (151.1 examples/sec; 3.388 sec/batch)
2017-04-04 04:03:15.977075: step 570, loss = 11.55 (149.6 examples/sec; 3.423 sec/batch)
2017-04-04 04:03:49.593274: step 580, loss = 11.59 (149.4 examples/sec; 3.426 sec/batch)
2017-04-04 04:04:22.840160: step 590, loss = 11.68 (154.7 examples/sec; 3.310 sec/batch)
2017-04-04 04:04:56.281678: step 600, loss = 11.32 (150.9 examples/sec; 3.393 sec/batch)
2017-04-04 04:05:34.153540: step 610, loss = 11.27 (151.5 examples/sec; 3.380 sec/batch)
2017-04-04 04:06:07.682325: step 620, loss = 11.53 (151.9 examples/sec; 3.371 sec/batch)
2017-04-04 04:06:41.893133: step 630, loss = 11.53 (151.7 examples/sec; 3.376 sec/batch)
2017-04-04 04:07:15.586012: step 640, loss = 11.42 (152.7 examples/sec; 3.353 sec/batch)
2017-04-04 04:07:49.020768: step 650, loss = 11.10 (154.1 examples/sec; 3.322 sec/batch)
2017-04-04 04:08:23.004615: step 660, loss = 11.25 (141.7 examples/sec; 3.614 sec/batch)
2017-04-04 04:08:56.527176: step 670, loss = 11.51 (152.4 examples/sec; 3.358 sec/batch)
2017-04-04 04:09:29.771259: step 680, loss = 11.23 (154.6 examples/sec; 3.312 sec/batch)
2017-04-04 04:10:03.749221: step 690, loss = 11.70 (150.4 examples/sec; 3.405 sec/batch)
2017-04-04 04:10:37.265476: step 700, loss = 11.21 (154.8 examples/sec; 3.308 sec/batch)
2017-04-04 04:11:15.037387: step 710, loss = 11.15 (153.8 examples/sec; 3.329 sec/batch)
2017-04-04 04:11:48.314035: step 720, loss = 11.67 (153.3 examples/sec; 3.340 sec/batch)
2017-04-04 04:12:21.793539: step 730, loss = 11.27 (155.1 examples/sec; 3.301 sec/batch)
2017-04-04 04:12:55.219953: step 740, loss = 11.12 (154.3 examples/sec; 3.318 sec/batch)
2017-04-04 04:13:28.966384: step 750, loss = 11.36 (151.2 examples/sec; 3.386 sec/batch)
2017-04-04 04:14:02.788830: step 760, loss = 11.21 (151.5 examples/sec; 3.379 sec/batch)
2017-04-04 04:14:36.466805: step 770, loss = 11.26 (153.6 examples/sec; 3.332 sec/batch)
2017-04-04 04:15:10.080951: step 780, loss = 11.23 (153.9 examples/sec; 3.326 sec/batch)
2017-04-04 04:15:43.442269: step 790, loss = 11.06 (152.7 examples/sec; 3.353 sec/batch)
2017-04-04 04:16:17.036899: step 800, loss = 11.30 (151.7 examples/sec; 3.376 sec/batch)